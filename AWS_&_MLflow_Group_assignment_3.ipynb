{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Endikamichelena/M6---AWS-MLflow/blob/main/AWS_%26_MLflow_Group_assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task\n",
        "\n",
        "1. Select one of your previous projects that includes a machine learning component and use MLflow to track and manage your machine learning experiments. The following tasks should be performed:\n",
        "\n",
        "2. Train a machine learning model using the data from your previous project. You can use any machine learning model that is appropriate for your data and problem.\n",
        "\n",
        "3. Use MLflow to track and manage your machine learning experiments. Log the hyperparameters, metrics, and artifacts of your machine learning experiments in MLflow. Save structured and unstructured information related to your trained model in SQLite within MLflow.\n",
        "\n",
        "4. Optionally, prepare an ML app based on three layers (data, business, presentation) to provide a user-friendly interface for interacting with your machine learning model. This will involve creating a data layer that handles the data processing pipeline and provides functions for loading and preprocessing the data, a business layer that implements the machine learning model and its related functions, and a presentation layer that implements the user interface and connects it to the business layer."
      ],
      "metadata": {
        "id": "q3Xc0Q3dQb4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Layer: Setting up SQLite  "
      ],
      "metadata": {
        "id": "bFoMTQffN-gH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "First, let's create a SQLite database for the penguin dataset. SQLite is a lightweight, easy-to-use, serverless SQL database engine.\n",
        "\n",
        "Create a new file named database.py."
      ],
      "metadata": {
        "id": "9EiYT-HKWICp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zUFGk_fdQa06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3398cff7-296d-4a7d-9ae3-229bb0d9e53d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!pip install mlflow --q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# database.py\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load data\n",
        "data = pd.read_csv(\"https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv\")\n",
        "data = data.dropna()\n",
        "\n",
        "def init_db():\n",
        "  # load the penguin dataset into a Pandas DataFrame\n",
        "  df = data[['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g', 'species_short']]\n",
        "\n",
        "  # connect to the SQLite database\n",
        "  conn = sqlite3.connect(\"penguin.db\")\n",
        "\n",
        "  # save the Pandas DataFrame to the SQLite database\n",
        "  df.to_sql(\"penguin\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "  # close the connection to the SQLite database\n",
        "  conn.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_db()"
      ],
      "metadata": {
        "id": "xsP2EizWWHKn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run database.py to create the database and the penguin_data table."
      ],
      "metadata": {
        "id": "3lo31iLYYsg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# connect to the SQLite database\n",
        "conn = sqlite3.connect(\"penguin.db\")\n",
        "\n",
        "# read the list of tables using Pandas\n",
        "tables_df = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "\n",
        "# print the table names\n",
        "for table_name in tables_df['name']:\n",
        "    print(table_name)\n",
        "\n",
        "# close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs6v4q7eXMUA",
        "outputId": "fff572cc-8fbb-486c-a2b6-28423cce02f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "penguin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Layer: Training the Machine Learning Model"
      ],
      "metadata": {
        "id": "2KSMxHXYQlmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the scikit-learn library to train a machine learning model for Penguin classification. \n",
        "\n",
        "Create a new file named ml_model.py and paste the following code:"
      ],
      "metadata": {
        "id": "DwfzSTIkXY-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "# connect to the SQLite database\n",
        "conn = sqlite3.connect(\"penguin.db\")\n",
        "\n",
        "# read data from a table using Pandas\n",
        "data_df = pd.read_sql(\"SELECT * FROM penguin\", conn)\n",
        "\n",
        "def train_model():\n",
        "    X = data_df.drop('species_short', axis=1)\n",
        "    y = data_df['species_short']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    clf = SVC()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    with open(\"model.pkl\", \"wb\") as f:\n",
        "        pickle.dump(clf, f)\n",
        "\n",
        "    return clf.score(X_test, y_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    accuracy = train_model()\n",
        "    print(f\"Model trained with accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb4jUyTWXpsa",
        "outputId": "0dafe343-57b1-40c6-b89b-fee95bbec0db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained with accuracy: 0.7313432835820896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentation Layer: HTML & CSS"
      ],
      "metadata": {
        "id": "tltiwNZKQwXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new folder named templates, and inside it, create a new file named index.html.\n"
      ],
      "metadata": {
        "id": "u6_DBzigaR69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Penguin Classification</title>\n",
        "    <link rel=\"stylesheet\" href=\"static/style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Penguin Classification</h1>\n",
        "    <form action=\"/classify\" method=\"post\">\n",
        "        <label for=\"culmen_length_mm\">culmen_length:</label>\n",
        "        <input type=\"number\" step=\"0.1\" id=\"culmen_length_mm\" name=\"culmen_length_mm\" required><br><br>\n",
        "        <label for=\"culmen_depth_mm\">culmen_depth:</label>\n",
        "        <input type=\"number\" step=\"0.1\" id=\"culmen_depth_mm\" name=\"culmen_depth_mm\" required><br><br>\n",
        "        <label for=\"flipper_length_mm\">flipper_length:</label>\n",
        "        <input type=\"number\" step=\"0.1\" id=\"flipper_length_mm\" name=\"flipper_length_mm\" required><br><br>\n",
        "        <label for=\"body_mass_g\">body_mass:</label>\n",
        "        <input type=\"number\" step=\"0.1\" id=\"body_mass_g\" name=\"body_mass_g\" required><br><br>\n",
        "        <input type=\"submit\" value=\"Classify\">\n",
        "    </form>\n",
        "    {% if prediction %}\n",
        "    <h2>Prediction: {{ prediction }}</h2>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "KYi_aTxAaW_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3a8d54d8-16f7-4768-8ef5-71f74bc1451a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-1bdeaf77d895>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <!DOCTYPE html>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a basic CSS file to style our app. \n",
        "\n",
        "Create a new folder named ***static***, and inside it, create a new file named ***style.css***.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fnld0WFLecoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "body {\n",
        "    font-family: Arial, sans-serif;\n",
        "    max-width: 600px;\n",
        "    margin: 0 auto;\n",
        "    padding: 20px;\n",
        "}\n",
        "\n",
        "input[type=number], input[type=submit] {\n",
        "    width: 100%;\n",
        "    padding: 5px;\n",
        "    margin: 5px 0;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        "\n",
        "input[type=submit] {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    cursor: pointer;\n",
        "}"
      ],
      "metadata": {
        "id": "OVKE1ScebfS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting everything with Flask"
      ],
      "metadata": {
        "id": "Q5swncQMQ7pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new file named ***app.py*** and paste."
      ],
      "metadata": {
        "id": "e1bjgz33bipg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "import pickle\n",
        "import sqlite3\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "with open(\"model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return render_template(\"index.html\", prediction=None)\n",
        "\n",
        "@app.route(\"/classify\", methods=[\"POST\"])\n",
        "def classify():\n",
        "    culmen_length_mm = float(request.form[\"culmen_length_mm\"])\n",
        "    culmen_depth_mm = float(request.form[\"culmen_depth_mm\"])\n",
        "    flipper_length_mm = float(request.form[\"flipper_length_mm\"])\n",
        "    body_mass_g = float(request.form[\"body_mass_g\"])\n",
        "\n",
        "    data = [[culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g]]\n",
        "    prediction = model.predict(data)[0]\n",
        "\n",
        "    # save the data to the database\n",
        "    connection = sqlite3.connect(\"penguin.db\")\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(\"INSERT INTO penguin (culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, species_short) VALUES (?, ?, ?, ?, ?)\",\n",
        "                   (culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, prediction))\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "    return jsonify({\"prediction\": prediction})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=5006)"
      ],
      "metadata": {
        "id": "QjClNvMnbf8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710c341d-1a95-440e-e3e1-7e02224de3e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5006\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLflow"
      ],
      "metadata": {
        "id": "zTMtRy1Ugc39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the RandomForestClassifier in our business layer."
      ],
      "metadata": {
        "id": "Z0H3kSNXRIEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# connect to the SQLite database\n",
        "conn = sqlite3.connect(\"penguin.db\")\n",
        "\n",
        "# read data from a table using Pandas\n",
        "data_df = pd.read_sql(\"SELECT * FROM penguin\", conn)\n",
        "\n",
        "def train_model():\n",
        "    mlflow.set_experiment(\"penguin_Classification\")\n",
        "    X = data_df.drop('species_short', axis=1)\n",
        "    y = data_df['species_short']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # log model parameters\n",
        "        mlflow.log_param(\"n_estimators\", clf.n_estimators)\n",
        "        mlflow.log_param(\"criterion\", clf.criterion)\n",
        "\n",
        "        # log model performance metrics\n",
        "        train_score = clf.score(X_train, y_train)\n",
        "        test_score = clf.score(X_test, y_test)\n",
        "        mlflow.log_metric(\"train_score\", train_score)\n",
        "        mlflow.log_metric(\"test_score\", test_score)\n",
        "\n",
        "        # save the model as an artifact\n",
        "        mlflow.sklearn.log_model(clf, \"model\")\n",
        "\n",
        "    return clf, test_score\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    clf, accuracy = train_model()\n",
        "    print(f\"Model trained with accuracy: {accuracy}\")\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.sklearn.log_model(clf, \"model\")\n",
        "    mlflow.sklearn.log_model(clf, \"model\", registered_model_name=\"penguin_model\")\n",
        "    mlflow.sklearn.save_model(clf, \"penguin_model_3\")\n",
        "\n",
        "    # launch MLflow UI\n",
        "    import os\n",
        "    os.system(\"mlflow ui\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eAL9lOag7lU",
        "outputId": "a2379a62-cca9-475a-90a2-104333bf4126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/04/18 16:53:54 INFO mlflow.tracking.fluent: Experiment with name 'penguin_Classification' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained with accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'penguin_model'.\n",
            "2023/04/18 16:54:04 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: penguin_model, version 1\n",
            "Created version '1' of model 'penguin_model'.\n"
          ]
        }
      ]
    }
  ]
}